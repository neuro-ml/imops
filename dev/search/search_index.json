{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Imops","text":"<p>Efficient parallelizable algorithms for multidimensional arrays to speed up your data pipelines</p>"},{"location":"#install","title":"Install","text":"<pre><code>pip install imops  # default install with Cython backend\npip install imops[numba]  # additionally install Numba backend\n</code></pre>"},{"location":"#functions","title":"Functions","text":""},{"location":"#imops.crop.crop_to_shape","title":"<code>imops.crop.crop_to_shape(x, shape, axis=None, ratio=0.5)</code>","text":"<p>Crop <code>x</code> to match <code>shape</code> along <code>axis</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>n-dimensional array</p> required <code>shape</code> <code>AxesLike</code> <p>final shape</p> required <code>axis</code> <code>AxesLike</code> <p>axis along which <code>x</code> will be padded</p> <code>None</code> <code>ratio</code> <code>AxesParams</code> <p>float or sequence of floats describing what proportion of cropping to apply on the left sides of cropping axes. Remaining ratio of cropping will be applied on the right sides</p> <code>0.5</code> <p>Returns:</p> Name Type Description <code>cropped</code> <code>ndarray</code> <p>cropped array</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x  # array of shape [2, 3, 4]\n&gt;&gt;&gt; cropped = crop_to_shape(x, [1, 2, 3], ratio=0)  # crop to shape [1, 2, 3] from the right\n&gt;&gt;&gt; cropped = crop_to_shape(x, 2, axis=1, ratio=1)  # crop to shape [2, 2, 4] from the left\n&gt;&gt;&gt; cropped = crop_to_shape(x, [3, 4, 5])  # fail due to bigger resulting shape\n</code></pre> Source code in <code>imops/crop.py</code> <pre><code>def crop_to_shape(x: np.ndarray, shape: AxesLike, axis: AxesLike = None, ratio: AxesParams = 0.5) -&gt; np.ndarray:\n    \"\"\"\n    Crop `x` to match `shape` along `axis`.\n\n    Parameters\n    ----------\n    x: np.ndarray\n        n-dimensional array\n    shape: AxesLike\n        final shape\n    axis: AxesLike\n        axis along which `x` will be padded\n    ratio: AxesParams\n        float or sequence of floats describing what proportion of cropping to apply on the left sides of cropping axes.\n        Remaining ratio of cropping will be applied on the right sides\n\n    Returns\n    -------\n    cropped: np.ndarray\n        cropped array\n\n    Examples\n    --------\n    &gt;&gt;&gt; x  # array of shape [2, 3, 4]\n    &gt;&gt;&gt; cropped = crop_to_shape(x, [1, 2, 3], ratio=0)  # crop to shape [1, 2, 3] from the right\n    &gt;&gt;&gt; cropped = crop_to_shape(x, 2, axis=1, ratio=1)  # crop to shape [2, 2, 4] from the left\n    &gt;&gt;&gt; cropped = crop_to_shape(x, [3, 4, 5])  # fail due to bigger resulting shape\n    \"\"\"\n    x = np.asarray(x)\n    axis, shape, ratio = broadcast_axis(axis, x.ndim, shape, ratio)\n\n    old_shape, new_shape = np.array(x.shape), np.array(fill_by_indices(x.shape, shape, axis))\n    if (old_shape &lt; new_shape).any():\n        raise ValueError(f'The resulting shape cannot be greater than the original one: {old_shape} vs {new_shape}.')\n\n    ndim = len(x.shape)\n    ratio = fill_by_indices(np.zeros(ndim), ratio, axis)\n    start = ((old_shape - new_shape) * ratio).astype(int)\n\n    # TODO: Create contiguous array?\n    return x[tuple(map(slice, start, start + new_shape))]\n</code></pre>"},{"location":"#imops.crop.crop_to_box","title":"<code>imops.crop.crop_to_box(x, box, axis=None, padding_values=None, num_threads=_NUMERIC_DEFAULT_NUM_THREADS, backend=None)</code>","text":"<p>Crop <code>x</code> according to <code>box</code> along <code>axis</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>n-dimensional array</p> required <code>box</code> <code>ndarray</code> <p>array of shape (2, x.ndim or len(axis) if axis is passed) describing crop boundaries</p> required <code>axis</code> <code>AxesLike</code> <p>axis along which <code>x</code> will be cropped</p> <code>None</code> <code>padding_values</code> <code>AxesParams</code> <p>values to pad with if box exceeds the input's limits</p> <code>None</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = 4. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>_NUMERIC_DEFAULT_NUM_THREADS</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Returns:</p> Name Type Description <code>cropped</code> <code>ndarray</code> <p>cropped array</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x  # array of shape [2, 3, 4]\n&gt;&gt;&gt; cropped = crop_to_box(x, np.array([[0, 0, 0], [1, 1, 1]]))  # crop to shape [1, 1, 1]\n&gt;&gt;&gt; cropped = crop_to_box(x, np.array([[0, 0, 0], [5, 5, 5]]))  # fail, box exceeds the input's limits\n&gt;&gt;&gt; cropped = crop_to_box(x, np.array([[0], [5]]), axis=0, padding_values=0)  # pad with 0-s to shape [5, 3, 4]\n</code></pre> Source code in <code>imops/crop.py</code> <pre><code>def crop_to_box(\n    x: np.ndarray,\n    box: np.ndarray,\n    axis: AxesLike = None,\n    padding_values: AxesParams = None,\n    num_threads: int = _NUMERIC_DEFAULT_NUM_THREADS,\n    backend: BackendLike = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Crop `x` according to `box` along `axis`.\n\n    Parameters\n    ----------\n    x: np.ndarray\n        n-dimensional array\n    box: np.ndarray\n        array of shape (2, x.ndim or len(axis) if axis is passed) describing crop boundaries\n    axis: AxesLike\n        axis along which `x` will be cropped\n    padding_values: AxesParams\n        values to pad with if box exceeds the input's limits\n    num_threads: int\n        the number of threads to use for computation. Default = 4. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `cython` and `scipy` are available, `cython` is used by default\n\n    Returns\n    -------\n    cropped: np.ndarray\n        cropped array\n\n    Examples\n    --------\n    &gt;&gt;&gt; x  # array of shape [2, 3, 4]\n    &gt;&gt;&gt; cropped = crop_to_box(x, np.array([[0, 0, 0], [1, 1, 1]]))  # crop to shape [1, 1, 1]\n    &gt;&gt;&gt; cropped = crop_to_box(x, np.array([[0, 0, 0], [5, 5, 5]]))  # fail, box exceeds the input's limits\n    &gt;&gt;&gt; cropped = crop_to_box(x, np.array([[0], [5]]), axis=0, padding_values=0)  # pad with 0-s to shape [5, 3, 4]\n    \"\"\"\n    x = np.asarray(x)\n    start, stop = box\n    axis, start, stop = broadcast_axis(axis, x.ndim, start, stop)\n\n    slice_start = np.maximum(start, 0)\n    slice_stop = np.minimum(stop, np.array(x.shape)[list(axis)])\n    padding = np.array([slice_start - start, stop - slice_stop], dtype=int).T\n\n    if padding_values is None and padding.any():\n        raise ValueError(f\"The box {box} exceeds the input's limits {x.shape}.\")\n\n    slice_start = fill_by_indices(np.zeros(x.ndim, int), slice_start, axis)\n    slice_stop = fill_by_indices(x.shape, slice_stop, axis)\n    # TODO: Create contiguous array?\n    x = x[tuple(map(slice, slice_start, slice_stop))]\n\n    if padding_values is not None and padding.any():\n        x = pad(x, padding, axis, padding_values, num_threads=num_threads, backend=backend)\n\n    return x\n</code></pre>"},{"location":"#imops.pad.pad","title":"<code>imops.pad.pad(x, padding, axis=None, padding_values=0, num_threads=_NUMERIC_DEFAULT_NUM_THREADS, backend=None)</code>","text":"<p>Pad <code>x</code> according to <code>padding</code> along the <code>axis</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>n-dimensional array to pad</p> required <code>padding</code> <code>Union[AxesLike, Sequence[Sequence[int]]]</code> <p>if 2D array [[start_1, stop_1], ..., [start_n, stop_n]] - specifies individual padding for each axis from <code>axis</code>. The length of the array must either be equal to 1 or match the length of <code>axis</code>. If 1D array [val_1, ..., val_n] - same as [[val_1, val_1], ..., [val_n, val_n]]. If scalar (val) - same as [[val, val]]</p> required <code>axis</code> <code>AxesLike</code> <p>axis along which <code>x</code> will be padded</p> <code>None</code> <code>padding_values</code> <code>Union[AxesParams, Callable]</code> <p>values to pad with, must be broadcastable to the resulting array. If Callable (e.g. <code>numpy.min</code>) - <code>padding_values(x)</code> will be used</p> <code>0</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = 4. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>_NUMERIC_DEFAULT_NUM_THREADS</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Returns:</p> Name Type Description <code>padded</code> <code>ndarray</code> <p>padded array</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; padded = pad(x, 2)  # pad 2 zeros on each side of each axes\n&gt;&gt;&gt; padded = pad(x, [1, 1], axis=(-1, -2))  # pad 1 zero on each side of last 2 axes\n</code></pre> Source code in <code>imops/pad.py</code> <pre><code>def pad(\n    x: np.ndarray,\n    padding: Union[AxesLike, Sequence[Sequence[int]]],\n    axis: AxesLike = None,\n    padding_values: Union[AxesParams, Callable] = 0,\n    num_threads: int = _NUMERIC_DEFAULT_NUM_THREADS,\n    backend: BackendLike = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Pad `x` according to `padding` along the `axis`.\n\n    Parameters\n    ----------\n    x: np.ndarray\n        n-dimensional array to pad\n    padding: Union[AxesLike, Sequence[Sequence[int]]]\n        if 2D array [[start_1, stop_1], ..., [start_n, stop_n]] - specifies individual padding\n        for each axis from `axis`. The length of the array must either be equal to 1 or match the length of `axis`.\n        If 1D array [val_1, ..., val_n] - same as [[val_1, val_1], ..., [val_n, val_n]].\n        If scalar (val) - same as [[val, val]]\n    axis: AxesLike\n        axis along which `x` will be padded\n    padding_values: Union[AxesParams, Callable]\n        values to pad with, must be broadcastable to the resulting array.\n        If Callable (e.g. `numpy.min`) - `padding_values(x)` will be used\n    num_threads: int\n        the number of threads to use for computation. Default = 4. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `cython` and `scipy` are available, `cython` is used by default\n\n    Returns\n    -------\n    padded: np.ndarray\n        padded array\n\n    Examples\n    --------\n    &gt;&gt;&gt; padded = pad(x, 2)  # pad 2 zeros on each side of each axes\n    &gt;&gt;&gt; padded = pad(x, [1, 1], axis=(-1, -2))  # pad 1 zero on each side of last 2 axes\n    \"\"\"\n    x = np.asarray(x)\n    padding = np.asarray(padding)\n    if padding.ndim &lt; 2:\n        padding = padding.reshape(-1, 1)\n    axis = axis_from_dim(axis, x.ndim)\n    padding = np.asarray(fill_by_indices(np.zeros((x.ndim, 2), dtype=int), np.atleast_2d(padding), axis))\n    if (padding &lt; 0).any():\n        raise ValueError(f'Padding must be non-negative: {padding.tolist()}.')\n    if callable(padding_values):\n        padding_values = padding_values(x)\n\n    new_shape = np.array(x.shape) + np.sum(padding, axis=1)\n    new_x = np.array(padding_values, dtype=x.dtype)\n    new_x = copy(np.broadcast_to(new_x, new_shape), order='C', num_threads=num_threads, backend=backend)\n\n    start = padding[:, 0]\n    end = np.where(padding[:, 1] != 0, -padding[:, 1], None)\n    # TODO: how to parallelize this?\n    new_x[tuple(map(slice, start, end))] = x\n\n    return new_x\n</code></pre>"},{"location":"#imops.pad.pad_to_shape","title":"<code>imops.pad.pad_to_shape(x, shape, axis=None, padding_values=0, ratio=0.5, num_threads=_NUMERIC_DEFAULT_NUM_THREADS, backend=None)</code>","text":"<p>Pad <code>x</code> to match <code>shape</code> along the <code>axis</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>n-dimensional array to pad</p> required <code>shape</code> <code>AxesLike</code> <p>final shape</p> required <code>axis</code> <code>AxesLike</code> <p>axis along which <code>x</code> will be padded</p> <code>None</code> <code>padding_values</code> <code>Union[AxesParams, Callable]</code> <p>values to pad with, must be broadcastable to the resulting array. If Callable (e.g. <code>numpy.min</code>) - <code>padding_values(x)</code> will be used</p> <code>0</code> <code>ratio</code> <code>AxesParams</code> <p>float or sequence of floats describing what proportion of padding to apply on the left sides of padding axes. Remaining ratio of padding will be applied on the right sides</p> <code>0.5</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = 4. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>_NUMERIC_DEFAULT_NUM_THREADS</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Returns:</p> Name Type Description <code>padded</code> <code>ndarray</code> <p>padded array</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; padded = pad_to_shape(x, [4, 5, 6])  # pad 3d array\n&gt;&gt;&gt; padded = pad_to_shape(x, [4, 5], axis=[0, 1], ratio=0)  # pad first 2 axes on the right\n</code></pre> Source code in <code>imops/pad.py</code> <pre><code>def pad_to_shape(\n    x: np.ndarray,\n    shape: AxesLike,\n    axis: AxesLike = None,\n    padding_values: Union[AxesParams, Callable] = 0,\n    ratio: AxesParams = 0.5,\n    num_threads: int = _NUMERIC_DEFAULT_NUM_THREADS,\n    backend: BackendLike = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Pad `x` to match `shape` along the `axis`.\n\n    Parameters\n    ----------\n    x: np.ndarray\n        n-dimensional array to pad\n    shape: AxesLike\n        final shape\n    axis: AxesLike\n        axis along which `x` will be padded\n    padding_values: Union[AxesParams, Callable]\n        values to pad with, must be broadcastable to the resulting array.\n        If Callable (e.g. `numpy.min`) - `padding_values(x)` will be used\n    ratio: AxesParams\n        float or sequence of floats describing what proportion of padding to apply on the left sides of padding axes.\n        Remaining ratio of padding will be applied on the right sides\n    num_threads: int\n        the number of threads to use for computation. Default = 4. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `cython` and `scipy` are available, `cython` is used by default\n\n    Returns\n    -------\n    padded: np.ndarray\n        padded array\n\n    Examples\n    --------\n    &gt;&gt;&gt; padded = pad_to_shape(x, [4, 5, 6])  # pad 3d array\n    &gt;&gt;&gt; padded = pad_to_shape(x, [4, 5], axis=[0, 1], ratio=0)  # pad first 2 axes on the right\n    \"\"\"\n    x = np.asarray(x)\n    axis, shape, ratio = broadcast_axis(axis, x.ndim, shape, ratio)\n\n    old_shape = np.array(x.shape)[list(axis)]\n    if (old_shape &gt; shape).any():\n        shape = fill_by_indices(x.shape, shape, axis)\n        raise ValueError(f'The resulting shape cannot be smaller than the original: {x.shape} vs {shape}.')\n\n    delta = shape - old_shape\n    start = (delta * ratio).astype(int)\n    padding = np.array((start, delta - start)).T.astype(int)\n\n    return pad(x, padding, axis, padding_values=padding_values, num_threads=num_threads, backend=backend)\n</code></pre>"},{"location":"#imops.pad.pad_to_divisible","title":"<code>imops.pad.pad_to_divisible(x, divisor, axis=None, padding_values=0, ratio=0.5, remainder=0, num_threads=_NUMERIC_DEFAULT_NUM_THREADS, backend=None)</code>","text":"<p>Pad <code>x</code> to be divisible by <code>divisor</code> along the <code>axis</code>.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>n-dimensional array to pad</p> required <code>divisor</code> <code>AxesLike</code> <p>float or sequence of floats an incoming array shape will be divisible by</p> required <code>axis</code> <code>AxesLike</code> <p>axis along which the array will be padded. If None - the last <code>len(divisor)</code> axes are used</p> <code>None</code> <code>padding_values</code> <code>Union[AxesParams, Callable]</code> <p>values to pad with. If Callable (e.g. <code>numpy.min</code>) - <code>padding_values(x)</code> will be used</p> <code>0</code> <code>ratio</code> <code>AxesParams</code> <p>float or sequence of floats describing what proportion of padding to apply on the left sides of padding axes. Remaining ratio of padding will be applied on the right sides</p> <code>0.5</code> <code>remainder</code> <code>AxesLike</code> <p><code>x</code> will be padded such that its shape gives the remainder <code>remainder</code> when divided by <code>divisor</code></p> <code>0</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = 4. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>_NUMERIC_DEFAULT_NUM_THREADS</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Returns:</p> Name Type Description <code>padded</code> <code>ndarray</code> <p>padded array</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x  # array of shape [2, 3, 4]\n&gt;&gt;&gt; padded = pad_to_divisible(x, 6)  # pad to shape [6, 6, 6]\n&gt;&gt;&gt; padded = pad_to_divisible(x, [4, 3], axis=[0, 1], ratio=1)  # pad first 2 axes on the left, shape - [4, 3, 4]\n&gt;&gt;&gt; padded = pad_to_divisible(x, 3, remainder=1)  # pad to shape [4, 4, 4]\n</code></pre> Source code in <code>imops/pad.py</code> <pre><code>def pad_to_divisible(\n    x: np.ndarray,\n    divisor: AxesLike,\n    axis: AxesLike = None,\n    padding_values: Union[AxesParams, Callable] = 0,\n    ratio: AxesParams = 0.5,\n    remainder: AxesLike = 0,\n    num_threads: int = _NUMERIC_DEFAULT_NUM_THREADS,\n    backend: BackendLike = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Pad `x` to be divisible by `divisor` along the `axis`.\n\n    Parameters\n    ----------\n    x: np.ndarray\n        n-dimensional array to pad\n    divisor: AxesLike\n        float or sequence of floats an incoming array shape will be divisible by\n    axis: AxesLike\n        axis along which the array will be padded. If None - the last `len(divisor)` axes are used\n    padding_values: Union[AxesParams, Callable]\n        values to pad with. If Callable (e.g. `numpy.min`) - `padding_values(x)` will be used\n    ratio: AxesParams\n        float or sequence of floats describing what proportion of padding to apply on the left sides of padding axes.\n        Remaining ratio of padding will be applied on the right sides\n    remainder: AxesLike\n        `x` will be padded such that its shape gives the remainder `remainder` when divided by `divisor`\n    num_threads: int\n        the number of threads to use for computation. Default = 4. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `cython` and `scipy` are available, `cython` is used by default\n\n    Returns\n    -------\n    padded: np.ndarray\n        padded array\n\n    Examples\n    --------\n    &gt;&gt;&gt; x  # array of shape [2, 3, 4]\n    &gt;&gt;&gt; padded = pad_to_divisible(x, 6)  # pad to shape [6, 6, 6]\n    &gt;&gt;&gt; padded = pad_to_divisible(x, [4, 3], axis=[0, 1], ratio=1)  # pad first 2 axes on the left, shape - [4, 3, 4]\n    &gt;&gt;&gt; padded = pad_to_divisible(x, 3, remainder=1)  # pad to shape [4, 4, 4]\n    \"\"\"\n    x = np.asarray(x)\n    axis = axis_from_dim(axis, x.ndim)\n    divisor, remainder, ratio = broadcast_to_axis(axis, divisor, remainder, ratio)\n\n    assert np.all(remainder &gt;= 0)\n    shape = np.maximum(np.array(x.shape)[list(axis)], remainder)\n\n    return pad_to_shape(\n        x, shape + (remainder - shape) % divisor, axis, padding_values, ratio, num_threads=num_threads, backend=backend\n    )\n</code></pre>"},{"location":"#imops.pad.restore_crop","title":"<code>imops.pad.restore_crop(x, box, shape, padding_values=0, num_threads=_NUMERIC_DEFAULT_NUM_THREADS, backend=None)</code>","text":"<p>Pad <code>x</code> to match <code>shape</code>. The left padding is taken equal to <code>box</code>'s start.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>n-dimensional array to pad</p> required <code>box</code> <code>ndarray</code> <p>array of shape (2, x.ndim) describing crop boundaries</p> required <code>shape</code> <code>AxesLike</code> <p>shape to restore crop to</p> required <code>padding_values</code> <code>Union[AxesParams, Callable]</code> <p>values to pad with. If Callable (e.g. <code>numpy.min</code>) - <code>padding_values(x)</code> will be used</p> <code>0</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = 4. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>_NUMERIC_DEFAULT_NUM_THREADS</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Returns:</p> Name Type Description <code>padded</code> <code>ndarray</code> <p>padded array</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x  # array of shape [2, 3, 4]\n&gt;&gt;&gt; padded = restore_crop(x, np.array([[0, 0, 0], [2, 3, 4]]), [4, 4, 4])  # pad to shape [4, 4, 4]\n&gt;&gt;&gt; padded = restore_crop(x, np.array([[0, 0, 0], [1, 1, 1]]), [4, 4, 4])  # fail, box is inconsistent with an array\n&gt;&gt;&gt; padded = restore_crop(x, np.array([[1, 2, 3], [3, 5, 7]]), [3, 5, 7])  # pad to shape [3, 5, 7]\n</code></pre> Source code in <code>imops/pad.py</code> <pre><code>def restore_crop(\n    x: np.ndarray,\n    box: np.ndarray,\n    shape: AxesLike,\n    padding_values: Union[AxesParams, Callable] = 0,\n    num_threads: int = _NUMERIC_DEFAULT_NUM_THREADS,\n    backend: BackendLike = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Pad `x` to match `shape`. The left padding is taken equal to `box`'s start.\n\n    Parameters\n    ----------\n    x: np.ndarray\n        n-dimensional array to pad\n    box: np.ndarray\n        array of shape (2, x.ndim) describing crop boundaries\n    shape: AxesLike\n        shape to restore crop to\n    padding_values: Union[AxesParams, Callable]\n        values to pad with. If Callable (e.g. `numpy.min`) - `padding_values(x)` will be used\n    num_threads: int\n        the number of threads to use for computation. Default = 4. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `cython` and `scipy` are available, `cython` is used by default\n\n    Returns\n    -------\n    padded: np.ndarray\n        padded array\n\n    Examples\n    --------\n    &gt;&gt;&gt; x  # array of shape [2, 3, 4]\n    &gt;&gt;&gt; padded = restore_crop(x, np.array([[0, 0, 0], [2, 3, 4]]), [4, 4, 4])  # pad to shape [4, 4, 4]\n    &gt;&gt;&gt; padded = restore_crop(x, np.array([[0, 0, 0], [1, 1, 1]]), [4, 4, 4])  # fail, box is inconsistent with an array\n    &gt;&gt;&gt; padded = restore_crop(x, np.array([[1, 2, 3], [3, 5, 7]]), [3, 5, 7])  # pad to shape [3, 5, 7]\n    \"\"\"\n    start, stop = np.asarray(box)\n\n    assert len(shape) == x.ndim\n    assert len(start) == len(stop) == x.ndim\n\n    x = np.asarray(x)\n\n    if (stop &gt; shape).any() or (stop - start != x.shape).any():\n        raise ValueError(\n            f'The input array (of shape {x.shape}) was not obtained by cropping a '\n            f'box {start, stop} from the shape {shape}.'\n        )\n\n    padding = np.array([start, shape - stop], dtype=int).T\n    x = pad(x, padding, padding_values=padding_values, num_threads=num_threads, backend=backend)\n    assert all(np.array(x.shape) == shape)\n\n    return x\n</code></pre>"},{"location":"#imops.zoom.zoom","title":"<code>imops.zoom.zoom(x, scale_factor, axis=None, order=1, fill_value=0, num_threads=-1, backend=None)</code>","text":"<p>Rescale <code>x</code> according to <code>scale_factor</code> along the <code>axis</code>.</p> <p>Uses a fast parallelizable implementation for fp32 / fp64 (and bool-int16-32-64 if order == 0) inputs, ndim &lt;= 4 and order = 0 or 1.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>n-dimensional array</p> required <code>scale_factor</code> <code>AxesParams</code> <p>float or sequence of floats describing how to scale along axes</p> required <code>axis</code> <code>AxesLike</code> <p>axis along which array will be scaled</p> <code>None</code> <code>order</code> <code>int</code> <p>order of interpolation</p> <code>1</code> <code>fill_value</code> <code>Union[float, Callable]</code> <p>value to fill past edges. If Callable (e.g. <code>numpy.min</code>) - <code>fill_value(x)</code> will be used</p> <code>0</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = the cpu count. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>-1</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>numba</code>, <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Returns:</p> Name Type Description <code>zoomed</code> <code>ndarray</code> <p>zoomed array</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; zoomed = zoom(x, 2, axis=[0, 1])  # 3d array\n&gt;&gt;&gt; zoomed = zoom(x, [1, 2, 3])  # different scales along each axes\n&gt;&gt;&gt; zoomed = zoom(x.astype(int))  # will fall back to scipy's implementation because of int dtype\n</code></pre> Source code in <code>imops/zoom.py</code> <pre><code>def zoom(\n    x: np.ndarray,\n    scale_factor: AxesParams,\n    axis: AxesLike = None,\n    order: int = 1,\n    fill_value: Union[float, Callable] = 0,\n    num_threads: int = -1,\n    backend: BackendLike = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Rescale `x` according to `scale_factor` along the `axis`.\n\n    Uses a fast parallelizable implementation for fp32 / fp64 (and bool-int16-32-64 if order == 0) inputs,\n    ndim &lt;= 4 and order = 0 or 1.\n\n    Parameters\n    ----------\n    x: np.ndarray\n        n-dimensional array\n    scale_factor: AxesParams\n        float or sequence of floats describing how to scale along axes\n    axis: AxesLike\n        axis along which array will be scaled\n    order: int\n        order of interpolation\n    fill_value: float | Callable\n        value to fill past edges. If Callable (e.g. `numpy.min`) - `fill_value(x)` will be used\n    num_threads: int\n        the number of threads to use for computation. Default = the cpu count. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `numba`, `cython` and `scipy` are available, `cython` is used by default\n\n    Returns\n    -------\n    zoomed: np.ndarray\n        zoomed array\n\n    Examples\n    --------\n    &gt;&gt;&gt; zoomed = zoom(x, 2, axis=[0, 1])  # 3d array\n    &gt;&gt;&gt; zoomed = zoom(x, [1, 2, 3])  # different scales along each axes\n    &gt;&gt;&gt; zoomed = zoom(x.astype(int))  # will fall back to scipy's implementation because of int dtype\n    \"\"\"\n    x = np.asarray(x)\n    axis, scale_factor = broadcast_axis(axis, x.ndim, scale_factor)\n    scale_factor = fill_by_indices(np.ones(x.ndim, 'float64'), scale_factor, axis)\n\n    if callable(fill_value):\n        fill_value = fill_value(x)\n\n    # TODO: does `fill_value/cval` change anythng?\n    return _zoom(x, scale_factor, order=order, cval=fill_value, num_threads=num_threads, backend=backend)\n</code></pre>"},{"location":"#imops.zoom.zoom_to_shape","title":"<code>imops.zoom.zoom_to_shape(x, shape, axis=None, order=1, fill_value=0, num_threads=-1, backend=None)</code>","text":"<p>Rescale <code>x</code> to match <code>shape</code> along the <code>axis</code>.</p> <p>Uses a fast parallelizable implementation for fp32 / fp64 (and bool-int16-32-64 if order == 0) inputs, ndim &lt;= 4 and order = 0 or 1.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>n-dimensional array</p> required <code>shape</code> <code>AxesLike</code> <p>float or sequence of floats describing desired lengths along axes</p> required <code>axis</code> <code>AxesLike</code> <p>axis along which array will be scaled</p> <code>None</code> <code>order</code> <code>int</code> <p>order of interpolation</p> <code>1</code> <code>fill_value</code> <code>Union[float, Callable]</code> <p>value to fill past edges. If Callable (e.g. <code>numpy.min</code>) - <code>fill_value(x)</code> will be used</p> <code>0</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = the cpu count. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>-1</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>numba</code>, <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Returns:</p> Name Type Description <code>zoomed</code> <code>ndarray</code> <p>zoomed array</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; zoomed = zoom_to_shape(x, [3, 4, 5])  # 3d array\n&gt;&gt;&gt; zoomed = zoom_to_shape(x, [6, 7], axis=[1, 2])  # zoom to shape along specified axes\n&gt;&gt;&gt; zoomed = zoom_to_shape(x.astype(int))  # will fall back to scipy's implementation because of int dtype\n</code></pre> Source code in <code>imops/zoom.py</code> <pre><code>def zoom_to_shape(\n    x: np.ndarray,\n    shape: AxesLike,\n    axis: AxesLike = None,\n    order: int = 1,\n    fill_value: Union[float, Callable] = 0,\n    num_threads: int = -1,\n    backend: BackendLike = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Rescale `x` to match `shape` along the `axis`.\n\n    Uses a fast parallelizable implementation for fp32 / fp64 (and bool-int16-32-64 if order == 0) inputs,\n    ndim &lt;= 4 and order = 0 or 1.\n\n    Parameters\n    ----------\n    x: np.ndarray\n        n-dimensional array\n    shape: AxesLike\n        float or sequence of floats describing desired lengths along axes\n    axis: AxesLike\n        axis along which array will be scaled\n    order: int\n        order of interpolation\n    fill_value: float | Callable\n        value to fill past edges. If Callable (e.g. `numpy.min`) - `fill_value(x)` will be used\n    num_threads: int\n        the number of threads to use for computation. Default = the cpu count. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `numba`, `cython` and `scipy` are available, `cython` is used by default\n\n    Returns\n    -------\n    zoomed: np.ndarray\n        zoomed array\n\n    Examples\n    --------\n    &gt;&gt;&gt; zoomed = zoom_to_shape(x, [3, 4, 5])  # 3d array\n    &gt;&gt;&gt; zoomed = zoom_to_shape(x, [6, 7], axis=[1, 2])  # zoom to shape along specified axes\n    &gt;&gt;&gt; zoomed = zoom_to_shape(x.astype(int))  # will fall back to scipy's implementation because of int dtype\n    \"\"\"\n    x = np.asarray(x)\n    axis, shape = broadcast_axis(axis, x.ndim, shape)\n    old_shape = np.array(x.shape, 'float64')\n    new_shape = np.array(fill_by_indices(x.shape, shape, axis), 'float64')\n\n    return zoom(\n        x,\n        new_shape / old_shape,\n        range(x.ndim),\n        order=order,\n        fill_value=fill_value,\n        num_threads=num_threads,\n        backend=backend,\n    )\n</code></pre>"},{"location":"#imops.interp1d.interp1d","title":"<code>imops.interp1d.interp1d</code>","text":"<p>Faster parallelizable version of <code>scipy.interpolate.interp1d</code> for fp32 / fp64 inputs.</p> <p>Works faster only for ndim &lt;= 3. Shares interface with <code>scipy.interpolate.interp1d</code> except for <code>num_threads</code> and <code>backend</code> arguments.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>1-dimensional array of real values (aka coordinates)</p> required <code>y</code> <code>ndarray</code> <p>n-dimensional array of real values. The length of y along the interpolation axis must be equal to the x length</p> required <code>kind</code> <code>Union[int, str]</code> <p>specifies the kind of interpolation as a string or as an integer specifying the order of interpolation to use. Only kind=1 and 'linear<code>are fast and parallelizable, other kinds will force to use</code>scipy` implementation</p> <code>'linear'</code> <code>axis</code> <code>int</code> <p>specifies the axis of y along which to interpolate. Interpolation defaults to the last axis of y</p> <code>-1</code> <code>copy</code> <code>bool</code> <p>if True, the class makes internal copies of x and y. If False, references to x and y are used</p> <code>True</code> <code>bounds_error</code> <code>bool</code> <p>if True, a ValueError is raised any time interpolation is attempted on a value outside of the range of x where extrapolation is necessary. If False, out of bounds values are assigned fill_value. By default, an error is raised unless fill_value='extrapolate'</p> <code>None</code> <code>fill_value</code> <code>Union[float, str]</code> <p>if a float, this value will be used to fill in for requested points outside of the data range. If not provided, then the default is NaN. If 'extrapolate', values for points outside of the data range will be extrapolated</p> <code>nan</code> <code>assume_sorted</code> <code>bool</code> <p>if False, values of x can be in any order and they are sorted first. If True, x has to be an array of monotonically increasing values</p> <code>False</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = the cpu count. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>-1</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>numba</code>, <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Methods:</p> Name Description <code>__call__</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from imops.interp1d import interp1d\n&gt;&gt;&gt; x = np.arange(0, 10)\n&gt;&gt;&gt; y = np.exp(-x/3.0)\n&gt;&gt;&gt; f = interp1d(x, y)\n&gt;&gt;&gt; xnew = np.arange(0, 9, 0.1)\n&gt;&gt;&gt; ynew = f(xnew)   # use interpolation function returned by `interp1d`\n</code></pre> Source code in <code>imops/interp1d.py</code> <pre><code>class interp1d:\n    \"\"\"\n    Faster parallelizable version of `scipy.interpolate.interp1d` for fp32 / fp64 inputs.\n\n    Works faster only for ndim &lt;= 3. Shares interface with `scipy.interpolate.interp1d` except for `num_threads` and\n    `backend` arguments.\n\n    Parameters\n    ----------\n    x: np.ndarray\n        1-dimensional array of real values (aka coordinates)\n    y: np.ndarray\n        n-dimensional array of real values. The length of y along the interpolation axis must be equal to the x length\n    kind: Union[int, str]\n        specifies the kind of interpolation as a string or as an integer specifying the order of interpolation to use.\n        Only kind=1 and 'linear` are fast and parallelizable, other kinds will force to use `scipy` implementation\n    axis: int\n        specifies the axis of y along which to interpolate. Interpolation defaults to the last axis of y\n    copy: bool\n        if True, the class makes internal copies of x and y. If False, references to x and y are used\n    bounds_error: bool\n        if True, a ValueError is raised any time interpolation is attempted on a value outside of the range of x where\n        extrapolation is necessary. If False, out of bounds values are assigned fill_value. By default, an error is\n        raised unless fill_value='extrapolate'\n    fill_value: Union[float, str]\n        if a float, this value will be used to fill in for requested points outside of the data range. If not provided,\n        then the default is NaN. If 'extrapolate', values for points outside of the data range will be extrapolated\n    assume_sorted: bool\n        if False, values of x can be in any order and they are sorted first. If True, x has to be an array of\n        monotonically increasing values\n    num_threads: int\n        the number of threads to use for computation. Default = the cpu count. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `numba`, `cython` and `scipy` are available, `cython` is used by default\n\n    Methods\n    -------\n    __call__\n\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; from imops.interp1d import interp1d\n    &gt;&gt;&gt; x = np.arange(0, 10)\n    &gt;&gt;&gt; y = np.exp(-x/3.0)\n    &gt;&gt;&gt; f = interp1d(x, y)\n    &gt;&gt;&gt; xnew = np.arange(0, 9, 0.1)\n    &gt;&gt;&gt; ynew = f(xnew)   # use interpolation function returned by `interp1d`\n    \"\"\"\n\n    def __init__(\n        self,\n        x: np.ndarray,\n        y: np.ndarray,\n        kind: Union[int, str] = 'linear',\n        axis: int = -1,\n        copy: bool = True,\n        bounds_error: bool = None,\n        fill_value: Union[float, str] = np.nan,\n        assume_sorted: bool = False,\n        num_threads: int = -1,\n        backend: BackendLike = None,\n    ) -&gt; None:\n        backend = resolve_backend(backend, warn_stacklevel=3)\n        if backend.name not in ('Scipy', 'Numba', 'Cython'):\n            raise ValueError(f'Unsupported backend \"{backend.name}\".')\n\n        self.backend = backend\n        self.dtype = y.dtype\n        self.num_threads = num_threads\n\n        if backend.name == 'Scipy':\n            self.scipy_interp1d = scipy_interp1d(x, y, kind, axis, copy, bounds_error, fill_value, assume_sorted)\n        elif self.dtype not in (np.float32, np.float64) or y.ndim &gt; 3 or kind not in ('linear', 1):\n            warn(\n                \"Fast interpolation is only supported for ndim&lt;=3, dtype=float32 or float64, order=1 or 'linear'. \"\n                \"Falling back to scipy's implementation.\",\n                stacklevel=2,\n            )\n            self.scipy_interp1d = scipy_interp1d(x, y, kind, axis, copy, bounds_error, fill_value, assume_sorted)\n        else:\n            if len(x) != y.shape[axis]:\n                raise ValueError(\n                    f'x and y arrays must be equal in length along interpolation axis: {len(x)} vs {y.shape[axis]}.'\n                )\n\n            if bounds_error and fill_value == 'extrapolate':\n                raise ValueError('Cannot extrapolate and raise at the same time.')\n\n            if fill_value == 'extrapolate' and len(x) &lt; 2 or y.shape[axis] &lt; 2:\n                raise ValueError('x and y arrays must have at least 2 entries.')\n\n            if fill_value == 'extrapolate':\n                self.bounds_error = False\n            else:\n                self.bounds_error = True if bounds_error is None else bounds_error\n\n            self.axis = axis\n\n            if axis not in (-1, y.ndim - 1):\n                y = np.swapaxes(y, -1, axis)\n\n            self.fill_value = fill_value\n            self.scipy_interp1d = None\n            # FIXME: how to accurately pass `num_threads` and `backend` arguments to `copy`?\n            self.x = _copy(x, order='C') if copy else x\n            self.n_dummy = 3 - y.ndim\n            self.y = y[(None,) * self.n_dummy] if self.n_dummy else y\n\n            if copy:\n                self.y = _copy(self.y, order='C')\n\n            self.assume_sorted = assume_sorted\n\n            if backend.name == 'Cython':\n                self.src_interp1d = cython_fast_interp1d if backend.fast else cython_interp1d\n\n            if backend.name == 'Numba':\n                from numba import njit\n\n                from .src._numba_zoom import _interp1d as numba_interp1d\n\n                njit_kwargs = {kwarg: getattr(backend, kwarg) for kwarg in backend.__dataclass_fields__.keys()}\n                self.src_interp1d = njit(**njit_kwargs)(numba_interp1d)\n\n    def __call__(self, x_new: np.ndarray, use_torch: bool = False) -&gt; np.ndarray:\n        if use_torch:\n            import torch\n        \"\"\"\n        Evaluate the interpolant\n\n        Parameters\n        ----------\n        x_new: np.ndarray\n            1d array points to evaluate the interpolant at.\n\n        Returns\n        -------\n        y_new: np.ndarray\n            interpolated values. Shape is determined by replacing the interpolation axis in the original array with\n            the shape of x\n        \"\"\"\n        num_threads = normalize_num_threads(self.num_threads, self.backend, warn_stacklevel=3)\n\n        if self.scipy_interp1d is not None:\n            return self.scipy_interp1d(x_new)\n\n        extrapolate = self.fill_value == 'extrapolate'\n        args = () if self.backend.name in ('Numba',) else (num_threads,)\n\n        if self.backend.name == 'Numba':\n            from numba import get_num_threads, set_num_threads\n\n            old_num_threads = get_num_threads()\n            set_num_threads(num_threads)\n        # TODO: Figure out how to properly handle multiple type signatures in Cython and remove `.astype`-s\n        out = self.src_interp1d(\n            self.y,\n            self.x.astype(np.float64, copy=False),\n            x_new.astype(np.float64, copy=False),\n            self.bounds_error,\n            0.0 if extrapolate else self.fill_value,\n            extrapolate,\n            self.assume_sorted,\n            *args,\n        )\n\n        if self.backend.name == 'Numba':\n            set_num_threads(old_num_threads)\n\n        if use_torch:\n            out = torch.from_numpy(out).to(max(torch.from_numpy(self.y).dtype, torch.from_numpy(self.x).dtype, torch.from_numpy(x_new).dtype, key=lambda x: x.itemsize)).numpy()\n        else:\n            out = out.astype(max(self.y.dtype, self.x.dtype, x_new.dtype, key=lambda x: x.type(0).itemsize), copy=False)\n\n        if self.n_dummy:\n            out = out[(0,) * self.n_dummy]\n        if self.axis not in (-1, out.ndim - 1):\n            out = np.swapaxes(out, -1, self.axis)\n        # FIXME: fix behaviour with np.inf-s\n        if use_torch:\n            have_nan = torch.isnan(torch.from_numpy(out)).any()\n        else:\n            have_nan = np.isnan(out).any()\n        if have_nan:\n            if not np.isinf(out).any():\n                raise RuntimeError(\"Can't decide how to handle nans in the output.\")\n\n            have_neg = np.isneginf(out).any()\n            have_pos = np.isposinf(out).any()\n\n            if have_pos and have_neg:\n                raise RuntimeError(\"Can't decide how to handle nans in the output.\")\n\n            if have_pos:\n                return np.nan_to_num(out, copy=False, nan=np.inf, posinf=np.inf)\n\n            return np.nan_to_num(out, copy=False, nan=-np.inf, neginf=-np.inf)\n\n        return out\n</code></pre>"},{"location":"#imops.interp1d.interp1d.__call__","title":"<code>__call__(x_new, use_torch=False)</code>","text":"Source code in <code>imops/interp1d.py</code> <pre><code>def __call__(self, x_new: np.ndarray, use_torch: bool = False) -&gt; np.ndarray:\n    if use_torch:\n        import torch\n    \"\"\"\n    Evaluate the interpolant\n\n    Parameters\n    ----------\n    x_new: np.ndarray\n        1d array points to evaluate the interpolant at.\n\n    Returns\n    -------\n    y_new: np.ndarray\n        interpolated values. Shape is determined by replacing the interpolation axis in the original array with\n        the shape of x\n    \"\"\"\n    num_threads = normalize_num_threads(self.num_threads, self.backend, warn_stacklevel=3)\n\n    if self.scipy_interp1d is not None:\n        return self.scipy_interp1d(x_new)\n\n    extrapolate = self.fill_value == 'extrapolate'\n    args = () if self.backend.name in ('Numba',) else (num_threads,)\n\n    if self.backend.name == 'Numba':\n        from numba import get_num_threads, set_num_threads\n\n        old_num_threads = get_num_threads()\n        set_num_threads(num_threads)\n    # TODO: Figure out how to properly handle multiple type signatures in Cython and remove `.astype`-s\n    out = self.src_interp1d(\n        self.y,\n        self.x.astype(np.float64, copy=False),\n        x_new.astype(np.float64, copy=False),\n        self.bounds_error,\n        0.0 if extrapolate else self.fill_value,\n        extrapolate,\n        self.assume_sorted,\n        *args,\n    )\n\n    if self.backend.name == 'Numba':\n        set_num_threads(old_num_threads)\n\n    if use_torch:\n        out = torch.from_numpy(out).to(max(torch.from_numpy(self.y).dtype, torch.from_numpy(self.x).dtype, torch.from_numpy(x_new).dtype, key=lambda x: x.itemsize)).numpy()\n    else:\n        out = out.astype(max(self.y.dtype, self.x.dtype, x_new.dtype, key=lambda x: x.type(0).itemsize), copy=False)\n\n    if self.n_dummy:\n        out = out[(0,) * self.n_dummy]\n    if self.axis not in (-1, out.ndim - 1):\n        out = np.swapaxes(out, -1, self.axis)\n    # FIXME: fix behaviour with np.inf-s\n    if use_torch:\n        have_nan = torch.isnan(torch.from_numpy(out)).any()\n    else:\n        have_nan = np.isnan(out).any()\n    if have_nan:\n        if not np.isinf(out).any():\n            raise RuntimeError(\"Can't decide how to handle nans in the output.\")\n\n        have_neg = np.isneginf(out).any()\n        have_pos = np.isposinf(out).any()\n\n        if have_pos and have_neg:\n            raise RuntimeError(\"Can't decide how to handle nans in the output.\")\n\n        if have_pos:\n            return np.nan_to_num(out, copy=False, nan=np.inf, posinf=np.inf)\n\n        return np.nan_to_num(out, copy=False, nan=-np.inf, neginf=-np.inf)\n\n    return out\n</code></pre>"},{"location":"#imops.morphology.binary_dilation","title":"<code>imops.morphology.binary_dilation(image, footprint=None, output=None, boxed=False, num_threads=-1, backend=None)</code>","text":"<p>Fast parallelizable binary morphological dilation of an image</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>input image</p> required <code>footprint</code> <code>ndarray</code> <p>the neighborhood expressed as a n-D array of 1's and 0's. If None, use a cross-shaped footprint (connectivity=1)</p> <code>None</code> <code>output</code> <code>ndarray</code> <p>array of the same shape as input, into which the output is placed (must be C-contiguous). By default, a new array is created</p> <code>None</code> <code>boxed</code> <code>bool</code> <p>if True, dilation is performed on cropped image which may speed up computation depedning on how localized True pixels are. This may induce differences with Scikit-Image implementation at border pixels if footprint is exotic (has even shape or center pixel is False)</p> <code>False</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = the cpu count. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>-1</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dilated</code> <code>ndarray</code> <p>the result of morphological dilation</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; dilated = binary_dilation(x)\n</code></pre> Source code in <code>imops/morphology.py</code> <pre><code>def binary_dilation(\n    image: np.ndarray,\n    footprint: np.ndarray = None,\n    output: np.ndarray = None,\n    boxed: bool = False,\n    num_threads: int = -1,\n    backend: BackendLike = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Fast parallelizable binary morphological dilation of an image\n\n    Parameters\n    ----------\n    image: np.ndarray\n        input image\n    footprint: np.ndarray\n        the neighborhood expressed as a n-D array of 1's and 0's. If None, use a cross-shaped footprint (connectivity=1)\n    output: np.ndarray\n        array of the same shape as input, into which the output is placed (must be C-contiguous). By default, a new\n        array is created\n    boxed: bool\n        if True, dilation is performed on cropped image which may speed up computation depedning on how localized True\n        pixels are. This may induce differences with Scikit-Image implementation at border pixels if footprint is\n        exotic (has even shape or center pixel is False)\n    num_threads: int\n        the number of threads to use for computation. Default = the cpu count. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `cython` and `scipy` are available, `cython` is used by default\n\n    Returns\n    -------\n    dilated: np.ndarray\n        the result of morphological dilation\n\n    Examples\n    --------\n    &gt;&gt;&gt; dilated = binary_dilation(x)\n    \"\"\"\n    return _binary_dilation(image, footprint, output, boxed, num_threads, backend)\n</code></pre>"},{"location":"#imops.morphology.binary_erosion","title":"<code>imops.morphology.binary_erosion(image, footprint=None, output=None, boxed=False, num_threads=-1, backend=None)</code>","text":"<p>Fast parallelizable binary morphological erosion of an image</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>input image</p> required <code>footprint</code> <code>ndarray</code> <p>the neighborhood expressed as a n-D array of 1's and 0's. If None, use a cross-shaped footprint (connectivity=1)</p> <code>None</code> <code>output</code> <code>ndarray</code> <p>array of the same shape as input, into which the output is placed (must be C-contiguous). By default, a new array is created</p> <code>None</code> <code>boxed</code> <code>bool</code> <p>if True, erosion is performed on cropped image which may speed up computation depedning on how localized True pixels are. This may induce differences with Scikit-Image implementation at border pixels if footprint is exotic (has even shape or center pixel is False)</p> <code>False</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = the cpu count. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>-1</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Returns:</p> Name Type Description <code>eroded</code> <code>ndarray</code> <p>the result of morphological erosion</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; eroded = binary_erosion(x)\n</code></pre> Source code in <code>imops/morphology.py</code> <pre><code>def binary_erosion(\n    image: np.ndarray,\n    footprint: np.ndarray = None,\n    output: np.ndarray = None,\n    boxed: bool = False,\n    num_threads: int = -1,\n    backend: BackendLike = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Fast parallelizable binary morphological erosion of an image\n\n    Parameters\n    ----------\n    image: np.ndarray\n        input image\n    footprint: np.ndarray\n        the neighborhood expressed as a n-D array of 1's and 0's. If None, use a cross-shaped footprint (connectivity=1)\n    output: np.ndarray\n        array of the same shape as input, into which the output is placed (must be C-contiguous). By default, a new\n        array is created\n    boxed: bool\n        if True, erosion is performed on cropped image which may speed up computation depedning on how localized True\n        pixels are. This may induce differences with Scikit-Image implementation at border pixels if footprint is\n        exotic (has even shape or center pixel is False)\n    num_threads: int\n        the number of threads to use for computation. Default = the cpu count. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `cython` and `scipy` are available, `cython` is used by default\n\n    Returns\n    -------\n    eroded: np.ndarray\n        the result of morphological erosion\n\n    Examples\n    --------\n    &gt;&gt;&gt; eroded = binary_erosion(x)\n    \"\"\"\n    return _binary_erosion(image, footprint, output, boxed, num_threads, backend)\n</code></pre>"},{"location":"#imops.morphology.binary_opening","title":"<code>imops.morphology.binary_opening(image, footprint=None, output=None, boxed=False, num_threads=-1, backend=None)</code>","text":"<p>Fast parallelizable binary morphological opening of an image</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>input image</p> required <code>footprint</code> <code>ndarray</code> <p>the neighborhood expressed as a n-D array of 1's and 0's. If None, use a cross-shaped footprint (connectivity=1)</p> <code>None</code> <code>output</code> <code>ndarray</code> <p>array of the same shape as input, into which the output is placed (must be C-contiguous). By default, a new array is created</p> <code>None</code> <code>boxed</code> <code>bool</code> <p>if True, opening is performed on cropped image which may speed up computation depedning on how localized True pixels are. This may induce differences with Scikit-Image implementation at border pixels if footprint is exotic (has even shape or center pixel is False)</p> <code>False</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = the cpu count. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>-1</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Returns:</p> Name Type Description <code>opened</code> <code>ndarray</code> <p>the result of morphological opening</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; opened = binary_opening(x)\n</code></pre> Source code in <code>imops/morphology.py</code> <pre><code>def binary_opening(\n    image: np.ndarray,\n    footprint: np.ndarray = None,\n    output: np.ndarray = None,\n    boxed: bool = False,\n    num_threads: int = -1,\n    backend: BackendLike = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Fast parallelizable binary morphological opening of an image\n\n    Parameters\n    ----------\n    image: np.ndarray\n        input image\n    footprint: np.ndarray\n        the neighborhood expressed as a n-D array of 1's and 0's. If None, use a cross-shaped footprint (connectivity=1)\n    output: np.ndarray\n        array of the same shape as input, into which the output is placed (must be C-contiguous). By default, a new\n        array is created\n    boxed: bool\n        if True, opening is performed on cropped image which may speed up computation depedning on how localized True\n        pixels are. This may induce differences with Scikit-Image implementation at border pixels if footprint is\n        exotic (has even shape or center pixel is False)\n    num_threads: int\n        the number of threads to use for computation. Default = the cpu count. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `cython` and `scipy` are available, `cython` is used by default\n\n    Returns\n    -------\n    opened: np.ndarray\n        the result of morphological opening\n\n    Examples\n    --------\n    &gt;&gt;&gt; opened = binary_opening(x)\n    \"\"\"\n\n    return _binary_opening(image, footprint, output, boxed, num_threads, backend)\n</code></pre>"},{"location":"#imops.morphology.binary_closing","title":"<code>imops.morphology.binary_closing(image, footprint=None, output=None, boxed=False, num_threads=-1, backend=None)</code>","text":"<p>Fast parallelizable binary morphological closing of an image</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>input image</p> required <code>footprint</code> <code>ndarray</code> <p>the neighborhood expressed as a n-D array of 1's and 0's. If None, use a cross-shaped footprint (connectivity=1)</p> <code>None</code> <code>output</code> <code>ndarray</code> <p>array of the same shape as input, into which the output is placed (must be C-contiguous). By default, a new array is created</p> <code>None</code> <code>boxed</code> <code>bool</code> <p>if True, closing is performed on cropped image which may speed up computation depedning on how localized True pixels are. This may induce differences with Scikit-Image implementation at border pixels if footprint is exotic (has even shape or center pixel is False)</p> <code>False</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = the cpu count. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>-1</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Returns:</p> Name Type Description <code>closed</code> <code>ndarray</code> <p>the result of morphological closing</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; closed = binary_closing(x)\n</code></pre> Source code in <code>imops/morphology.py</code> <pre><code>def binary_closing(\n    image: np.ndarray,\n    footprint: np.ndarray = None,\n    output: np.ndarray = None,\n    boxed: bool = False,\n    num_threads: int = -1,\n    backend: BackendLike = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Fast parallelizable binary morphological closing of an image\n\n    Parameters\n    ----------\n    image: np.ndarray\n        input image\n    footprint: np.ndarray\n        the neighborhood expressed as a n-D array of 1's and 0's. If None, use a cross-shaped footprint (connectivity=1)\n    output: np.ndarray\n        array of the same shape as input, into which the output is placed (must be C-contiguous). By default, a new\n        array is created\n    boxed: bool\n        if True, closing is performed on cropped image which may speed up computation depedning on how localized True\n        pixels are. This may induce differences with Scikit-Image implementation at border pixels if footprint is\n        exotic (has even shape or center pixel is False)\n    num_threads: int\n        the number of threads to use for computation. Default = the cpu count. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `cython` and `scipy` are available, `cython` is used by default\n\n    Returns\n    -------\n    closed: np.ndarray\n        the result of morphological closing\n\n    Examples\n    --------\n    &gt;&gt;&gt; closed = binary_closing(x)\n    \"\"\"\n\n    return _binary_closing(image, footprint, output, boxed, num_threads, backend)\n</code></pre>"},{"location":"#imops.measure.label","title":"<code>imops.measure.label(label_image, background=None, connectivity=None, return_num=False, return_labels=False, return_sizes=False, dtype=None)</code>","text":"<p>Fast version of <code>skimage.measure.label</code> which optionally returns number of connected components, labels and sizes. If 2 or more outputs are requested <code>NamedTuple</code> is returned.</p> <p>Parameters:</p> Name Type Description Default <code>label_image</code> <code>ndarray</code> <p>image to label</p> required <code>background</code> <code>int</code> <p>consider all pixels with this value as background pixels, and label them as 0. By default, 0-valued pixels are considered as background pixels</p> <code>None</code> <code>connectivity</code> <code>int</code> <p>maximum number of orthogonal hops to consider a pixel/voxel as a neighbor. Accepted values are ranging from 1 to input.ndim. If None, a full connectivity of input.ndim is used</p> <code>None</code> <code>return_num</code> <code>bool</code> <p>whether to return the number of connected components</p> <code>False</code> <code>return_labels</code> <code>bool</code> <p>whether to return assigned labels</p> <code>False</code> <code>return_sizes</code> <code>bool</code> <p>whether to return sizes of connected components (excluding background)</p> <code>False</code> <code>dtype</code> <code>type</code> <p>if specified, must be one of np.uint16, np.uint32 or np.uint64. If not specified, it will be automatically determined. Most of the time, you should leave this off so that the smallest safe dtype will be used. However, in some applications you can save an up-conversion in the next operation by outputting the appropriately sized type instead. Has no effect for python3.6</p> <code>None</code> <p>Returns:</p> Name Type Description <code>labeled_image</code> <code>ndarray</code> <p>array of np.uint16, np.uint32 or np.uint64 numbers depending on the number of connected components and <code>dtype</code></p> <code>num_components</code> <code>int</code> <p>number of connected components excluding background. Returned if <code>return_num</code> is True</p> <code>labels</code> <code>ndarray</code> <p>components labels. Returned if <code>return_labels</code> is True</p> <code>sizes</code> <code>ndarray</code> <p>components sizes. Returned if <code>return_sizes</code> is True</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; labeled = label(x)\n&gt;&gt;&gt; labeled, num_components, sizes = label(x, return_num=True, return_sizes=True)\n&gt;&gt;&gt; out = label(x, return_labels=True, return_sizes=True)\n&gt;&gt;&gt; out.labeled_image, out.labels, out.sizes  # output fields can be accessed this way\n</code></pre> Source code in <code>imops/measure.py</code> <pre><code>def label(\n    label_image: np.ndarray,\n    background: int = None,\n    connectivity: int = None,\n    return_num: bool = False,\n    return_labels: bool = False,\n    return_sizes: bool = False,\n    dtype: type = None,\n) -&gt; Union[np.ndarray, NamedTuple]:\n    \"\"\"\n    Fast version of `skimage.measure.label` which optionally returns number of connected components, labels and sizes.\n    If 2 or more outputs are requested `NamedTuple` is returned.\n\n    Parameters\n    ----------\n    label_image: np.ndarray\n        image to label\n    background: int\n        consider all pixels with this value as background pixels, and label them as 0. By default, 0-valued pixels are\n        considered as background pixels\n    connectivity: int\n        maximum number of orthogonal hops to consider a pixel/voxel as a neighbor. Accepted values are ranging from 1\n        to input.ndim. If None, a full connectivity of input.ndim is used\n    return_num: bool\n        whether to return the number of connected components\n    return_labels: bool\n        whether to return assigned labels\n    return_sizes: bool\n        whether to return sizes of connected components (excluding background)\n    dtype:\n        if specified, must be one of np.uint16, np.uint32 or np.uint64. If not specified, it will be automatically\n        determined. Most of the time, you should leave this off so that the smallest safe dtype will be used. However,\n        in some applications you can save an up-conversion in the next operation by outputting the appropriately sized\n        type instead. Has no effect for python3.6\n\n    Returns\n    -------\n    labeled_image: np.ndarray\n        array of np.uint16, np.uint32 or np.uint64 numbers depending on the number of connected components and\n        `dtype`\n    num_components: int\n        number of connected components excluding background. Returned if `return_num` is True\n    labels: np.ndarray\n        components labels. Returned if `return_labels` is True\n    sizes: np.ndarray\n        components sizes. Returned if `return_sizes` is True\n\n    Examples\n    --------\n    &gt;&gt;&gt; labeled = label(x)\n    &gt;&gt;&gt; labeled, num_components, sizes = label(x, return_num=True, return_sizes=True)\n    &gt;&gt;&gt; out = label(x, return_labels=True, return_sizes=True)\n    &gt;&gt;&gt; out.labeled_image, out.labels, out.sizes  # output fields can be accessed this way\n    \"\"\"\n    ndim = label_image.ndim\n    connectivity = connectivity or ndim\n\n    if not 1 &lt;= connectivity &lt;= ndim:\n        raise ValueError(f'Connectivity for {ndim}D image should be in [1, ..., {ndim}]. Got {connectivity}.')\n\n    if ndim &gt; 3:\n        warn(\"Fast label is only supported for ndim&lt;=3, Falling back to scikit-image's implementation.\", stacklevel=2)\n        labeled_image, num_components = skimage_label(\n            label_image, background=background, return_num=True, connectivity=connectivity\n        )\n        if dtype is not None:\n            labeled_image = labeled_image.astype(dtype, copy=False)\n    else:\n        if ndim == 1:\n            label_image = label_image[None]\n\n        if background:\n            label_image = remap(\n                label_image,\n                {background: 0, 0: background},\n                preserve_missing_labels=True,\n                in_place=False,\n            )\n\n        labeled_image, num_components = connected_components(\n            label_image,\n            connectivity=_SKIMAGE2CC3D[(ndim, connectivity)],\n            return_N=True,\n            **{'out_dtype': dtype} if python_version()[:3] != '3.6' else {},\n        )\n\n        if ndim == 1:\n            labeled_image = labeled_image[0]\n\n    res = [('labeled_image', labeled_image)]\n\n    if return_num:\n        res.append(('num_components', num_components))\n    if return_labels:\n        res.append(('labels', np.array(range(1, num_components + 1))))\n    if return_sizes:\n        _, sizes = unique(labeled_image, return_counts=True)\n        res.append(('sizes', sizes[1:] if 0 in labeled_image else sizes))\n\n    if len(res) == 1:\n        return labeled_image\n\n    return namedtuple('Labeling', [subres[0] for subres in res])(*[subres[1] for subres in res])\n</code></pre>"},{"location":"#imops.measure.center_of_mass","title":"<code>imops.measure.center_of_mass(array, labels=None, index=None, num_threads=-1, backend=None)</code>","text":"<p>Calculate the center of mass of the values.</p> <p>Works faster for ndim &lt;= 3</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>ndarray</code> <p>data from which to calculate center-of-mass. The masses can either be positive or negative</p> required <code>labels</code> <code>ndarray</code> <p>labels for objects in input, as generated by <code>imops.measure.label</code>. Dimensions must be the same as input. If specified, <code>index</code> also must be specified and have same dtype</p> <code>None</code> <code>index</code> <code>Union[int, Sequence[int]]</code> <p>labels for which to calculate centers-of-mass. If specified, <code>labels</code> also must be specified and have same dtype</p> <code>None</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = the cpu count. If negative value passed cpu count + num_threads + 1 threads will be used. If <code>labels</code> and <code>index</code> are specified, only 1 thread will be used</p> <code>-1</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Returns:</p> Name Type Description <code>center_of_mass</code> <code>tuple, or list of tuples</code> <p>coordinates of centers-of-mass</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; center = center_of_mass(np.ones((2, 2)))  # (0.5, 0.5)\n</code></pre> Source code in <code>imops/measure.py</code> <pre><code>def center_of_mass(\n    array: np.ndarray,\n    labels: np.ndarray = None,\n    index: Union[int, Sequence[int]] = None,\n    num_threads: int = -1,\n    backend: BackendLike = None,\n) -&gt; Union[Tuple[float, ...], List[Tuple[float, ...]]]:\n    \"\"\"\n    Calculate the center of mass of the values.\n\n    Works faster for ndim &lt;= 3\n\n    Parameters\n    ----------\n    array: np.ndarray\n        data from which to calculate center-of-mass. The masses can either be positive or negative\n    labels: np.ndarray\n        labels for objects in input, as generated by `imops.measure.label`. Dimensions must be the same as input. If\n        specified, `index` also must be specified and have same dtype\n    index: Union[int, Sequence[int]]\n        labels for which to calculate centers-of-mass. If specified, `labels` also must be specified and have same dtype\n    num_threads: int\n        the number of threads to use for computation. Default = the cpu count. If negative value passed\n        cpu count + num_threads + 1 threads will be used. If `labels` and `index` are specified, only 1 thread will be\n        used\n    backend: BackendLike\n        which backend to use. `cython` and `scipy` are available, `cython` is used by default\n\n    Returns\n    -------\n    center_of_mass: tuple, or list of tuples\n        coordinates of centers-of-mass\n\n    Examples\n    --------\n    &gt;&gt;&gt; center = center_of_mass(np.ones((2, 2)))  # (0.5, 0.5)\n    \"\"\"\n    if (labels is None) ^ (index is None):\n        raise ValueError('`labels` and `index` should be both specified or both not specified.')\n\n    backend = resolve_backend(backend, warn_stacklevel=3)\n\n    if backend.name not in ('Scipy', 'Cython'):\n        raise ValueError(f'Unsupported backend \"{backend.name}\".')\n\n    num_threads = normalize_num_threads(num_threads, backend, warn_stacklevel=3)\n\n    if backend.name == 'Scipy':\n        return scipy_center_of_mass(array, labels, index)\n\n    ndim = array.ndim\n    if ndim &gt; 3:\n        warn(\"Fast center-of-mass is only supported for ndim&lt;=3. Falling back to scipy's implementation.\", stacklevel=2)\n        return scipy_center_of_mass(array, labels, index)\n\n    if labels is None:\n        src_center_of_mass = _fast_center_of_mass if backend.fast else _center_of_mass\n    else:\n        is_sequence = isinstance(index, (Sequence, np.ndarray))\n        index = np.array([index] if not is_sequence else index)\n\n        if labels.shape != array.shape:\n            raise ValueError(f'`array` and `labels` must be the same shape, got {array.shape} and {labels.shape}.')\n\n        if labels.dtype != index.dtype:\n            raise ValueError(f'`labels` and `index` must have same dtype, got {labels.dtype} and {index.dtype}.')\n\n        if len(index) != len(unique(index.astype(int, copy=False))):\n            raise ValueError('`index` should consist of unique values.')\n\n        if num_threads &gt; 1:\n            warn('Using single-threaded implementation as `labels` and `index` are specified.', stacklevel=2)\n\n        src_center_of_mass = _fast_labeled_center_of_mass if backend.fast else _labeled_center_of_mass\n\n    if array.dtype != 'float64':\n        array = array.astype(float)\n\n    n_dummy = 3 - ndim\n    if n_dummy:\n        array = array[(None,) * n_dummy]\n\n    if labels is None:\n        return tuple(src_center_of_mass(array, num_threads))[n_dummy:]\n\n    output = [tuple(x)[n_dummy:] for x in src_center_of_mass(array, labels[(None,) * n_dummy], index)]\n\n    return output if is_sequence else output[0]\n</code></pre>"},{"location":"#imops.numeric.pointwise_add","title":"<code>imops.numeric.pointwise_add(nums, summand, output=None, num_threads=_NUMERIC_DEFAULT_NUM_THREADS, backend=None)</code>","text":"<p>Perform pointwise addition between array and array or scalar.</p> <p>Uses a fast parallelizable implementation for fp16-32-64 and int16-32-64 inputs and ndim &lt;= 4.</p> <p>Parameters:</p> Name Type Description Default <code>nums</code> <code>ndarray</code> <p>n-dimensional array</p> required <code>summand</code> <code>Union[array, int, float]</code> <p>array of the same shape or scalar</p> required <code>output</code> <code>ndarray</code> <p>array of the same shape as input, into which the output is placed. By default, a new array is created</p> <code>None</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = 4. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>_NUMERIC_DEFAULT_NUM_THREADS</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Returns:</p> Name Type Description <code>sum</code> <code>ndarray</code> <p>result of summation</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sum = pointwise_add(x, 1, x)  # inplace addition\n&gt;&gt;&gt; sum = pointwise_add(x, 1, backend='Scipy')  # just `np.add`\n&gt;&gt;&gt; sum = pointwise_add(x.astype('float32'), x.astype('float16'))  # will fail because of different dtypes\n</code></pre> Source code in <code>imops/numeric.py</code> <pre><code>def pointwise_add(\n    nums: np.ndarray,\n    summand: Union[np.array, int, float],\n    output: np.ndarray = None,\n    num_threads: int = _NUMERIC_DEFAULT_NUM_THREADS,\n    backend: BackendLike = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Perform pointwise addition between array and array or scalar.\n\n    Uses a fast parallelizable implementation for fp16-32-64 and int16-32-64 inputs and ndim &lt;= 4.\n\n    Parameters\n    ----------\n    nums: np.ndarray\n        n-dimensional array\n    summand: np.ndarray | int | float\n        array of the same shape or scalar\n    output: np.ndarray\n        array of the same shape as input, into which the output is placed. By default, a new\n        array is created\n    num_threads: int\n        the number of threads to use for computation. Default = 4. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `cython` and `scipy` are available, `cython` is used by default\n\n    Returns\n    -------\n    sum: np.ndarray\n        result of summation\n\n    Examples\n    --------\n    &gt;&gt;&gt; sum = pointwise_add(x, 1, x)  # inplace addition\n    &gt;&gt;&gt; sum = pointwise_add(x, 1, backend='Scipy')  # just `np.add`\n    &gt;&gt;&gt; sum = pointwise_add(x.astype('float32'), x.astype('float16'))  # will fail because of different dtypes\n    \"\"\"\n    backend = resolve_backend(backend, warn_stacklevel=3)\n    if backend.name not in ('Scipy', 'Cython'):\n        raise ValueError(f'Unsupported backend \"{backend.name}\".')\n\n    dtype = nums.dtype\n\n    if dtype not in _TYPES:\n        raise ValueError(f'Input array dtype must be one of {\", \".join(_STR_TYPES)}, got {dtype}.')\n\n    if output is None:\n        output = np.empty_like(nums, dtype=dtype)\n    elif output.shape != nums.shape:\n        raise ValueError(f'Input array and output array shapes must be the same, got {nums.shape} vs {output.shape}.')\n    elif dtype != output.dtype:\n        raise ValueError(f'Input array and output array dtypes must be the same, got {dtype} vs {output.dtype}.')\n\n    summand_is_array = isinstance(summand, np.ndarray)\n    if summand_is_array:\n        if dtype != summand.dtype:\n            raise ValueError(f'Input and summand arrays must have same dtypes, got {dtype} vs {summand.dtype}.')\n    elif not isinstance(summand, (*_TYPES, *(int, float))):\n        raise ValueError(f'Summand dtype must be one of {\", \".join(_STR_TYPES)}, got {type(summand)}.')\n    else:\n        summand = dtype.type(summand)\n\n    ndim = nums.ndim\n    num_threads = normalize_num_threads(num_threads, backend, warn_stacklevel=3)\n\n    if backend.name == 'Scipy' or ndim &gt; 4:\n        np.add(nums, summand, out=output)\n        return output\n\n    is_fp16 = dtype == np.float16\n    src_pointwise_add = _choose_cython_pointwise_add(ndim, summand_is_array, is_fp16, backend.fast)\n\n    n_dummy = 3 - ndim if ndim &lt;= 3 else 0\n\n    if n_dummy:\n        nums = nums[(None,) * n_dummy]\n        output = output[(None,) * n_dummy]\n        if summand_is_array:\n            summand = summand[(None,) * n_dummy]\n\n    if is_fp16:\n        output = src_pointwise_add(\n            nums.view(np.uint16), summand.view(np.uint16), output.view(np.uint16), num_threads\n        ).view(np.float16)\n    else:\n        output = src_pointwise_add(nums, summand, output, num_threads)\n\n    if n_dummy:\n        output = output[(0,) * n_dummy]\n\n    return output\n</code></pre>"},{"location":"#imops.numeric.fill_","title":"<code>imops.numeric.fill_(nums, value, num_threads=_NUMERIC_DEFAULT_NUM_THREADS, backend=None)</code>","text":"<p>Fill the array with a scalar value.</p> <p>Uses a fast parallelizable implementation for fp16-32-64 and int16-32-64 inputs and ndim &lt;= 4.</p> <p>Parameters:</p> Name Type Description Default <code>nums</code> <code>ndarray</code> <p>n-dimensional array</p> required <code>value</code> <code>Union[number, int, float]</code> <p>scalar</p> required <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = 4. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>_NUMERIC_DEFAULT_NUM_THREADS</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; fill_(x, 1)\n&gt;&gt;&gt; fill_(np.empty((2, 3, 4)), 42)\n&gt;&gt;&gt; fill_(x.astype('uint16'), 3)  # will fail because of unsupported uint16 dtype\n</code></pre> Source code in <code>imops/numeric.py</code> <pre><code>def fill_(\n    nums: np.ndarray,\n    value: Union[np.number, int, float],\n    num_threads: int = _NUMERIC_DEFAULT_NUM_THREADS,\n    backend: BackendLike = None,\n) -&gt; None:\n    \"\"\"\n    Fill the array with a scalar value.\n\n    Uses a fast parallelizable implementation for fp16-32-64 and int16-32-64 inputs and ndim &lt;= 4.\n\n    Parameters\n    ----------\n    nums: np.ndarray\n        n-dimensional array\n    value: np.number | int | float\n        scalar\n    num_threads: int\n        the number of threads to use for computation. Default = 4. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `cython` and `scipy` are available, `cython` is used by default\n\n    Examples\n    --------\n    &gt;&gt;&gt; fill_(x, 1)\n    &gt;&gt;&gt; fill_(np.empty((2, 3, 4)), 42)\n    &gt;&gt;&gt; fill_(x.astype('uint16'), 3)  # will fail because of unsupported uint16 dtype\n    \"\"\"\n    backend = resolve_backend(backend, warn_stacklevel=3)\n    if backend.name not in ('Scipy', 'Cython'):\n        raise ValueError(f'Unsupported backend \"{backend.name}\".')\n\n    ndim = nums.ndim\n    dtype = nums.dtype\n\n    if dtype not in _TYPES or backend.name == 'Scipy' or ndim &gt; 4:\n        nums.fill(value)\n        return\n\n    is_fp16 = dtype == np.float16\n    num_threads = normalize_num_threads(num_threads, backend, warn_stacklevel=3)\n    src_fill_ = _choose_cython_fill_(ndim, backend.fast)\n    value = dtype.type(value)\n\n    n_dummy = 3 - ndim if ndim &lt;= 3 else 0\n\n    if n_dummy:\n        nums = nums[(None,) * n_dummy]\n\n    if is_fp16:\n        src_fill_(nums.view(np.uint16), value.view(np.uint16), num_threads)\n    else:\n        src_fill_(nums, value, num_threads)\n\n    if n_dummy:\n        nums = nums[(0,) * n_dummy]\n</code></pre>"},{"location":"#imops.numeric.full","title":"<code>imops.numeric.full(shape, fill_value, dtype=None, order='C', num_threads=_NUMERIC_DEFAULT_NUM_THREADS, backend=None)</code>","text":"<p>Return a new array of given shape and dtype, filled with <code>fill_value</code>.</p> <p>Uses a fast parallelizable implementation for fp16-32-64 and int16-32-64 inputs and ndim &lt;= 4.</p> <p>Parameters:</p> Name Type Description Default <code>shape</code> <code>Union[int, Sequence[int]]</code> <p>desired shape</p> required <code>fill_value</code> <code>Union[number, int, float]</code> <p>scalar to fill array with</p> required <code>dtype</code> <code>Union[type, str]</code> <p>desired dtype to which <code>fill_value</code> will be casted. If not specified, <code>np.array(fill_value).dtype</code> will be used</p> <code>None</code> <code>order</code> <code>str</code> <p>whether to store multidimensional data in C or F contiguous order in memory</p> <code>'C'</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = 4. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>_NUMERIC_DEFAULT_NUM_THREADS</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; x = full((2, 3, 4), 1.0)  # same as `np.ones((2, 3, 4))`\n&gt;&gt;&gt; x = full((2, 3, 4), 1.5, dtype=int)  # same as np.ones((2, 3, 4), dtype=int)\n&gt;&gt;&gt; x = full((2, 3, 4), 1, dtype='uint16')  # will fail because of unsupported uint16 dtype\n</code></pre> Source code in <code>imops/numeric.py</code> <pre><code>def full(\n    shape: Union[int, Sequence[int]],\n    fill_value: Union[np.number, int, float],\n    dtype: Union[type, str] = None,\n    order: str = 'C',\n    num_threads: int = _NUMERIC_DEFAULT_NUM_THREADS,\n    backend: BackendLike = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Return a new array of given shape and dtype, filled with `fill_value`.\n\n    Uses a fast parallelizable implementation for fp16-32-64 and int16-32-64 inputs and ndim &lt;= 4.\n\n    Parameters\n    ----------\n    shape: int | Sequence[int]\n        desired shape\n    fill_value: np.number | int | float\n        scalar to fill array with\n    dtype: type | str\n        desired dtype to which `fill_value` will be casted. If not specified, `np.array(fill_value).dtype` will be used\n    order: str\n        whether to store multidimensional data in C or F contiguous order in memory\n    num_threads: int\n        the number of threads to use for computation. Default = 4. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `cython` and `scipy` are available, `cython` is used by default\n\n    Examples\n    --------\n    &gt;&gt;&gt; x = full((2, 3, 4), 1.0)  # same as `np.ones((2, 3, 4))`\n    &gt;&gt;&gt; x = full((2, 3, 4), 1.5, dtype=int)  # same as np.ones((2, 3, 4), dtype=int)\n    &gt;&gt;&gt; x = full((2, 3, 4), 1, dtype='uint16')  # will fail because of unsupported uint16 dtype\n    \"\"\"\n    dtype = dtype or np.array(fill_value).dtype\n\n    nums = np.empty(shape, dtype=dtype, order=order)\n    fill_value = nums.dtype.type(fill_value)\n\n    fill_(nums, fill_value, num_threads, backend)\n\n    return nums\n</code></pre>"},{"location":"#imops.numeric.copy","title":"<code>imops.numeric.copy(nums, output=None, order='K', num_threads=_NUMERIC_DEFAULT_NUM_THREADS, backend=None)</code>","text":"<p>Return copy of the given array.</p> <p>Uses a fast parallelizable implementation for fp16-32-64 and int16-32-64 inputs and ndim &lt;= 4.</p> <p>Parameters:</p> Name Type Description Default <code>nums</code> <code>ndarray</code> <p>n-dimensional array</p> required <code>output</code> <code>ndarray</code> <p>array of the same shape and dtype as input, into which the copy is placed. By default, a new array is created</p> <code>None</code> <code>order</code> <code>str</code> <p>controls the memory layout of the copy. <code>C</code> means C-order, <code>F</code> means F-order, <code>A</code> means <code>F</code> if a is Fortran contiguous, <code>C</code> otherwise. <code>K</code> means match the layout of a as closely as possible</p> <code>'K'</code> <code>num_threads</code> <code>int</code> <p>the number of threads to use for computation. Default = 4. If negative value passed cpu count + num_threads + 1 threads will be used</p> <code>_NUMERIC_DEFAULT_NUM_THREADS</code> <code>backend</code> <code>BackendLike</code> <p>which backend to use. <code>cython</code> and <code>scipy</code> are available, <code>cython</code> is used by default</p> <code>None</code> <p>Returns:</p> Name Type Description <code>copy</code> <code>ndarray</code> <p>copy of array</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; copied = copy(x)\n&gt;&gt;&gt; copied = copy(x, backend='Scipy')  # same as `np.copy`\n&gt;&gt;&gt; copy(x, output=y)  # copied into `y`\n</code></pre> Source code in <code>imops/numeric.py</code> <pre><code>def copy(\n    nums: np.ndarray,\n    output: np.ndarray = None,\n    order: str = 'K',\n    num_threads: int = _NUMERIC_DEFAULT_NUM_THREADS,\n    backend: BackendLike = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Return copy of the given array.\n\n    Uses a fast parallelizable implementation for fp16-32-64 and int16-32-64 inputs and ndim &lt;= 4.\n\n    Parameters\n    ----------\n    nums: np.ndarray\n        n-dimensional array\n    output: np.ndarray\n        array of the same shape and dtype as input, into which the copy is placed. By default, a new\n        array is created\n    order: str\n        controls the memory layout of the copy. `C` means C-order, `F` means F-order, `A` means `F` if a is Fortran\n        contiguous, `C` otherwise. `K` means match the layout of a as closely as possible\n    num_threads: int\n        the number of threads to use for computation. Default = 4. If negative value passed\n        cpu count + num_threads + 1 threads will be used\n    backend: BackendLike\n        which backend to use. `cython` and `scipy` are available, `cython` is used by default\n\n    Returns\n    -------\n    copy: np.ndarray\n        copy of array\n\n    Examples\n    --------\n    &gt;&gt;&gt; copied = copy(x)\n    &gt;&gt;&gt; copied = copy(x, backend='Scipy')  # same as `np.copy`\n    &gt;&gt;&gt; copy(x, output=y)  # copied into `y`\n    \"\"\"\n    backend = resolve_backend(backend, warn_stacklevel=3)\n    if backend.name not in ('Scipy', 'Cython'):\n        raise ValueError(f'Unsupported backend \"{backend.name}\".')\n\n    ndim = nums.ndim\n    dtype = nums.dtype\n    num_threads = normalize_num_threads(num_threads, backend, warn_stacklevel=3)\n\n    if output is None:\n        output = np.empty_like(nums, dtype=dtype, order=order)\n    elif output.shape != nums.shape:\n        raise ValueError(f'Input array and output array shapes must be the same, got {nums.shape} vs {output.shape}.')\n    elif dtype != output.dtype:\n        raise ValueError(f'Input array and output array dtypes must be the same, got {dtype} vs {output.dtype}.')\n\n    if dtype not in _TYPES or backend.name == 'Scipy' or ndim &gt; 4:\n        output = np.copy(nums, order=order)\n        return output\n\n    is_fp16 = dtype == np.float16\n    src_copy = _choose_cython_copy(ndim, is_fp16, backend.fast)\n\n    n_dummy = 3 - ndim if ndim &lt;= 3 else 0\n\n    if n_dummy:\n        nums = nums[(None,) * n_dummy]\n        output = output[(None,) * n_dummy]\n\n    if is_fp16:\n        src_copy(nums.view(np.uint16), output.view(np.uint16), num_threads)\n    else:\n        src_copy(nums, output, num_threads)\n\n    if n_dummy:\n        nums = nums[(0,) * n_dummy]\n        output = output[(0,) * n_dummy]\n\n    return output\n</code></pre>"},{"location":"#imops.radon.radon","title":"<code>imops.radon.radon(image, axes=None, theta=180, return_fill=False, num_threads=-1, backend=None)</code>","text":"<p>Fast implementation of Radon transform. Adapted from scikit-image.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ndarray</code> <p>an n-dimensional array with at least 2 axes</p> required <code>axes</code> <code>Tuple[int, int]</code> <p>the axes in the <code>image</code> along which the Radon transform will be applied. The <code>image</code> shape along the <code>axes</code> must be of the same length</p> <code>None</code> <code>theta</code> <code>Union[int, Sequence[float]]</code> <p>the angles for which the Radon transform will be computed. If it is an integer - the angles will be evenly distributed between 0 and 180, <code>theta</code> values in total</p> <code>180</code> <code>return_fill</code> <code>bool</code> <p>whether to return the value that fills the image outside the circle working area</p> <code>False</code> <code>num_threads</code> <code>int</code> <p>the number of threads to be used for parallel computation. By default - equals to the number of cpu cores</p> <code>-1</code> <code>backend</code> <code>BackendLike</code> <p>the execution backend. Currently only \"Cython\" is avaliable</p> <code>None</code> <p>Returns:</p> Name Type Description <code>sinogram</code> <code>ndarray</code> <p>the result of the Radon transform</p> <code>fill_value</code> <code>float</code> <p>the value that fills the image outside the circle working area. Returned only if <code>return_fill</code> is True</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; sinogram = radon(image)  # 2d image\n&gt;&gt;&gt; sinogram, fill_value = radon(image, return_fill=True)  # 2d image with fill value\n&gt;&gt;&gt; sinogram = radon(image, axes=(-2, -1))  # nd image\n</code></pre> Source code in <code>imops/radon.py</code> <pre><code>def radon(\n    image: np.ndarray,\n    axes: Tuple[int, int] = None,\n    theta: Union[int, Sequence[float]] = 180,\n    return_fill: bool = False,\n    num_threads: int = -1,\n    backend: BackendLike = None,\n) -&gt; Union[np.ndarray, Tuple[np.ndarray, float]]:\n    \"\"\"\n    Fast implementation of Radon transform. Adapted from scikit-image.\n\n    Parameters\n    ----------\n    image: np.ndarray\n        an n-dimensional array with at least 2 axes\n    axes: tuple[int, int]\n        the axes in the `image` along which the Radon transform will be applied.\n        The `image` shape along the `axes` must be of the same length\n    theta: int | Sequence[float]\n        the angles for which the Radon transform will be computed. If it is an integer - the angles will\n        be evenly distributed between 0 and 180, `theta` values in total\n    return_fill: bool\n        whether to return the value that fills the image outside the circle working area\n    num_threads: int\n        the number of threads to be used for parallel computation. By default - equals to the number of cpu cores\n    backend: str | Backend\n        the execution backend. Currently only \"Cython\" is avaliable\n\n    Returns\n    -------\n    sinogram: np.ndarray\n        the result of the Radon transform\n    fill_value: float\n        the value that fills the image outside the circle working area. Returned only if `return_fill` is True\n\n    Examples\n    --------\n    &gt;&gt;&gt; sinogram = radon(image)  # 2d image\n    &gt;&gt;&gt; sinogram, fill_value = radon(image, return_fill=True)  # 2d image with fill value\n    &gt;&gt;&gt; sinogram = radon(image, axes=(-2, -1))  # nd image\n    \"\"\"\n    backend = resolve_backend(backend, warn_stacklevel=3)\n    if backend.name not in ('Cython',):\n        raise ValueError(f'Unsupported backend \"{backend.name}\".')\n\n    image, axes, extra = normalize_axes(image, axes)\n    if image.shape[1] != image.shape[2]:\n        raise ValueError(\n            f'The image must be square along the provided axes ({axes}), but has shape: {image.shape[1:]}.'\n        )\n\n    if isinstance(theta, int):\n        theta = np.linspace(0, 180, theta, endpoint=False)\n\n    size = image.shape[1]\n    radius = size // 2\n    xs = np.arange(-radius, size - radius)\n    squared = xs**2\n    outside_circle = (squared[:, None] + squared[None, :]) &gt; radius**2\n    values = image[:, outside_circle]\n    min_, max_ = values.min(), values.max()\n    if max_ - min_ &gt; 0.1:\n        raise ValueError(\n            f'The image must be constant outside the circle. ' f'Got values ranging from {min_} to {max_}.'\n        )\n\n    if min_ != 0 or max_ != 0:\n        # FIXME: how to accurately pass `num_threads` and `backend` arguments to `copy`?\n        image = copy(image, order='C')\n        image[:, outside_circle] = 0\n\n    # TODO: f(arange)?\n    limits = ((squared[:, None] + squared[None, :]) &gt; (radius + 2) ** 2).sum(0) // 2\n\n    num_threads = normalize_num_threads(num_threads, backend, warn_stacklevel=3)\n\n    radon3d_ = fast_radon3d if backend.fast else radon3d\n\n    sinogram = radon3d_(image, np.deg2rad(theta, dtype=image.dtype), limits, num_threads)\n\n    result = restore_axes(sinogram, axes, extra)\n    if return_fill:\n        result = result, min_\n\n    return result\n</code></pre>"},{"location":"#imops.radon.inverse_radon","title":"<code>imops.radon.inverse_radon(sinogram, axes=None, theta=None, fill_value=0, a=0, b=1, num_threads=-1, backend=None)</code>","text":"<p>Fast implementation of inverse Radon transform. Adapted from scikit-image.</p> <p>Parameters:</p> Name Type Description Default <code>sinogram</code> <code>ndarray</code> <p>an n-dimensional array with at least 2 axes</p> required <code>axes</code> <code>Tuple[int, int]</code> <p>the axes in the <code>image</code> along which the inverse Radon transform will be applied</p> <code>None</code> <code>theta</code> <code>Union[int, Sequence[float]]</code> <p>the angles for which the inverse Radon transform will be computed. If it is an integer - the angles will be evenly distributed between 0 and 180, <code>theta</code> values in total</p> <code>None</code> <code>fill_value</code> <code>float</code> <p>the value that fills the image outside the circle working area. Can be returned by <code>radon</code></p> <code>0</code> <code>a</code> <code>float</code> <p>the first parameter of the sharpen filter</p> <code>0</code> <code>b</code> <code>float</code> <p>the second parameter of the sharpen filter</p> <code>1</code> <code>num_threads</code> <code>int</code> <p>the number of threads to be used for parallel computation. By default - equals to the number of cpu cores</p> <code>-1</code> <code>backend</code> <code>BackendLike</code> <p>the execution backend. Currently only \"Cython\" is avaliable</p> <code>None</code> <p>Returns:</p> Name Type Description <code>image</code> <code>ndarray</code> <p>the result of the inverse Radon transform</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; image = inverse_radon(sinogram)  # 2d image\n&gt;&gt;&gt; image = inverse_radon(sinogram, fill_value=-1000)  # 2d image with fill value\n&gt;&gt;&gt; image = inverse_radon(sinogram, axes=(-2, -1))  # nd image\n</code></pre> Source code in <code>imops/radon.py</code> <pre><code>def inverse_radon(\n    sinogram: np.ndarray,\n    axes: Tuple[int, int] = None,\n    theta: Union[int, Sequence[float]] = None,\n    fill_value: float = 0,\n    a: float = 0,\n    b: float = 1,\n    num_threads: int = -1,\n    backend: BackendLike = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Fast implementation of inverse Radon transform. Adapted from scikit-image.\n\n    Parameters\n    ----------\n    sinogram: np.ndarray\n        an n-dimensional array with at least 2 axes\n    axes: tuple[int, int]\n        the axes in the `image` along which the inverse Radon transform will be applied\n    theta: int | Sequence[float]\n        the angles for which the inverse Radon transform will be computed. If it is an integer - the angles will\n        be evenly distributed between 0 and 180, `theta` values in total\n    fill_value: float\n        the value that fills the image outside the circle working area. Can be returned by `radon`\n    a: float\n        the first parameter of the sharpen filter\n    b: float\n        the second parameter of the sharpen filter\n    num_threads: int\n        the number of threads to be used for parallel computation. By default - equals to the number of cpu cores\n    backend: str | Backend\n        the execution backend. Currently only \"Cython\" is avaliable\n\n    Returns\n    -------\n    image: np.ndarray\n        the result of the inverse Radon transform\n\n    Examples\n    --------\n    &gt;&gt;&gt; image = inverse_radon(sinogram)  # 2d image\n    &gt;&gt;&gt; image = inverse_radon(sinogram, fill_value=-1000)  # 2d image with fill value\n    &gt;&gt;&gt; image = inverse_radon(sinogram, axes=(-2, -1))  # nd image\n    \"\"\"\n    backend = resolve_backend(backend, warn_stacklevel=3)\n    if backend.name not in ('Cython',):\n        raise ValueError(f'Unsupported backend \"{backend.name}\".')\n\n    sinogram, axes, extra = normalize_axes(sinogram, axes)\n\n    if theta is None:\n        theta = sinogram.shape[-1]\n    if isinstance(theta, int):\n        theta = np.linspace(0, 180, theta, endpoint=False)\n\n    angles_count = len(theta)\n    if angles_count != sinogram.shape[-1]:\n        raise ValueError(\n            f'The given `theta` (size {angles_count}) does not match the number of '\n            f'projections in `sinogram` ({sinogram.shape[-1]}).'\n        )\n    output_size = sinogram.shape[1]\n    sinogram = _sinogram_circle_to_square(sinogram)\n\n    img_shape = sinogram.shape[1]\n    # Resize image to next power of two (but no less than 64) for\n    # Fourier analysis; speeds up Fourier and lessens artifacts\n    # TODO: why *2?\n    projection_size_padded = max(64, int(2 ** np.ceil(np.log2(2 * img_shape))))\n    pad_width = ((0, 0), (0, projection_size_padded - img_shape), (0, 0))\n    padded_sinogram = np.pad(sinogram, pad_width, mode='constant', constant_values=0)\n    fourier_filter = _smooth_sharpen_filter(projection_size_padded, a, b)\n\n    # Apply filter in Fourier domain\n    fourier_img = fft(padded_sinogram, axis=1) * fourier_filter\n    filtered_sinogram = np.real(ifft(fourier_img, axis=1)[:, :img_shape, :])\n\n    radius = output_size // 2\n    xs = np.arange(-radius, output_size - radius)\n    squared = xs**2\n    inside_circle = (squared[:, None] + squared[None, :]) &lt;= radius**2\n\n    dtype = sinogram.dtype\n    filtered_sinogram = filtered_sinogram.astype(dtype, copy=False)\n    theta, xs = np.deg2rad(theta, dtype=dtype), xs.astype(dtype, copy=False)\n\n    num_threads = normalize_num_threads(num_threads, backend, warn_stacklevel=3)\n\n    backprojection3d_ = fast_backprojection3d if backend.fast else backprojection3d\n\n    reconstructed = np.asarray(\n        backprojection3d_(filtered_sinogram, theta, xs, inside_circle, fill_value, img_shape, output_size, num_threads)\n    )\n\n    return restore_axes(reconstructed, axes, extra)\n</code></pre>"}]}